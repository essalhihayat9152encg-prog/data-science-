#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyse Pr√©dictive Compl√®te - Prix de Vente des Voitures
Regroupement de tous les codes du notebook Analyse_2.ipynb
Dataset: CAR DETAILS FROM CAR DEKHO.csv
Auteur: Analyse pr√©dictive regroup√©e
Date: 3 D√©cembre 2025
"""

# ============================================================================
# 1. IMPORT DES LIBRAIRIES
# ============================================================================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Ignorer les warnings
warnings.filterwarnings('ignore')

# Configuration matplotlib pour affichage inline
plt.style.use('default')
sns.set_palette("husl")

print("‚úÖ Toutes les librairies import√©es avec succ√®s")

# ============================================================================
# 2. CHARGEMENT ET EXPLORATION DES DONN√âES
# ============================================================================
print("\n" + "="*60)
print("2. CHARGEMENT DES DONN√âES")
print("="*60)

# Chargement du dataset
df = pd.read_csv('content/drive/MyDrive/pro/analyse/CAR DETAILS FROM CAR DEKHO.csv')
print(f"üìä Dataset charg√©: {df.shape[0]} lignes, {df.shape[1]} colonnes")
print("\nPremi√®res lignes:")
print(df.head())

# V√©rification des valeurs manquantes
print("\nüîç V√©rification des valeurs manquantes:")
print(df.isnull().sum())

# ============================================================================
# 3. PR√âPARATION DES DONN√âES
# ============================================================================
print("\n" + "="*60)
print("3. PR√âPARATION DES DONN√âES")
print("="*60)

# Copie du dataframe et suppression de la colonne 'name'
df_processed = df.copy()
df_processed = df_processed.drop('name', axis=1)

# Colonnes cat√©gorielles pour one-hot encoding
categorical_cols = ['fuel', 'seller_type', 'transmission', 'owner']

# Application de l'encodage one-hot
df_processed = pd.get_dummies(df_processed, columns=categorical_cols, drop_first=True)

print(f"üìà Dataset apr√®s pr√©processing: {df_processed.shape[0]} lignes, {df_processed.shape[1]} colonnes")
print("\nPremi√®res lignes apr√®s encodage:")
print(df_processed.head())

# S√©paration des features (X) et target (y)
X = df_processed.drop('selling_price', axis=1)
y = df_processed['selling_price']

# Split train/test 70/30
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

print(f"\nüéØ Dimensions apr√®s split:")
print(f"X_train: {X_train.shape}")
print(f"X_test: {X_test.shape}")
print(f"y_train: {y_train.shape}")
print(f"y_test: {y_test.shape}")

# ============================================================================
# 4. FONCTION D'√âVALUATION ET VISUALISATION
# ============================================================================
def evaluate_and_plot(model, X_train, X_test, y_train, y_test, model_name):
    """
    Entra√Æne un mod√®le, calcule les m√©triques et affiche un graphique.
    """
    # Entra√Ænement
    model.fit(X_train, y_train)
    
    # Pr√©dictions
    y_pred = model.predict(X_test)
    
    # M√©triques
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    
    print(f"\nüìä {model_name} - Performances:")
    print(f"   MSE: {mse:,.2f}")
    print(f"   RMSE: {rmse:,.0f}")
    print(f"   R¬≤: {r2:.3f}")
    
    # Visualisation
    plt.figure(figsize=(10, 6))
    plt.scatter(y_test, y_pred, alpha=0.6, label='Pr√©dit vs R√©el')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
             'r--', lw=2, label='Pr√©diction parfaite')
    plt.xlabel('Prix de vente r√©el')
    plt.ylabel('Prix de vente pr√©dit')
    plt.title(f'{model_name}: R√©el vs Pr√©dit')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    return {'MSE': mse, 'RMSE': rmse, 'R2': r2, 'model': model_name}

# ============================================================================
# 5. ENTRA√éNEMENT ET √âVALUATION DES MOD√àLES
# ============================================================================
print("\n" + "="*60)
print("4. ENTRA√éNEMENT DES MOD√àLES")
print("="*60)

# Dictionnaire pour stocker les performances
performance_metrics = {}

# 5.1 R√©gression Lin√©aire
print("\nüîπ 1. R√©gression Lin√©aire")
lr_model = LinearRegression()
perf_lr = evaluate_and_plot(lr_model, X_train, X_test, y_train, y_test, "R√©gression Lin√©aire")
performance_metrics['R√©gression Lin√©aire'] = perf_lr

# 5.2 R√©gression Ridge
print("\nüîπ 2. R√©gression Ridge")
ridge_model = Ridge(alpha=1.0)
perf_ridge = evaluate_and_plot(ridge_model, X_train, X_test, y_train, y_test, "R√©gression Ridge")
performance_metrics['R√©gression Ridge'] = perf_ridge

# 5.3 R√©gression Lasso
print("\nüîπ 3. R√©gression Lasso")
lasso_model = Lasso(alpha=1.0)
perf_lasso = evaluate_and_plot(lasso_model, X_train, X_test, y_train, y_test, "R√©gression Lasso")
performance_metrics['R√©gression Lasso'] = perf_lasso

# 5.4 Arbre de D√©cision
print("\nüîπ 4. Arbre de D√©cision")
dt_model = DecisionTreeRegressor(random_state=42)
perf_dt = evaluate_and_plot(dt_model, X_train, X_test, y_train, y_test, "Arbre de D√©cision")
performance_metrics['Arbre de D√©cision'] = perf_dt

# 5.5 For√™t Al√©atoire
print("\nüîπ 5. For√™t Al√©atoire")
rf_model = RandomForestRegressor(random_state=42)
perf_rf = evaluate_and_plot(rf_model, X_train, X_test, y_train, y_test, "For√™t Al√©atoire")
performance_metrics['For√™t Al√©atoire'] = perf_rf

# 5.6 Gradient Boosting
print("\nüîπ 6. Gradient Boosting")
gbr_model = GradientBoostingRegressor(random_state=42)
perf_gbr = evaluate_and_plot(gbr_model, X_train, X_test, y_train, y_test, "Gradient Boosting")
performance_metrics['Gradient Boosting'] = perf_gbr

# ============================================================================
# 6. COMPARAISON DES PERFORMANCES
# ============================================================================
print("\n" + "="*60)
print("5. COMPARAISON DES PERFORMANCES")
print("="*60)

# DataFrame de comparaison
perf_df = pd.DataFrame(performance_metrics).T
perf_df = perf_df.sort_values('R2', ascending=False)
perf_df = perf_df.round(4)

print("\nüèÜ Tableau de comparaison (tri√© par R¬≤ d√©croissant):")
print(perf_df)

# Sauvegarde des r√©sultats
perf_df.to_csv('performance_modeles_regression.csv', index=True)
print("\nüíæ R√©sultats sauvegard√©s dans 'performance_modeles_regression.csv'")

# Graphique de comparaison R¬≤
plt.figure(figsize=(12, 6))
models = perf_df.index
r2_scores = perf_df['R2']
colors = plt.cm.viridis(np.linspace(0, 1, len(models)))

bars = plt.bar(models, r2_scores, color=colors, alpha=0.8, edgecolor='black')
plt.xlabel('Mod√®les')
plt.ylabel('Score R¬≤')
plt.title('Comparaison des Scores R¬≤ par Mod√®le')
plt.xticks(rotation=45, ha='right')
plt.ylim(0, max(r2_scores)*1.1)
plt.grid(True, alpha=0.3, axis='y')

# Ajout des valeurs sur les barres
for bar, score in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()
plt.show()

# ============================================================================
# 7. CONCLUSION ET MEILLEUR MOD√àLE
# ============================================================================
print("\n" + "="*60)
print("6. CONCLUSION")
print("="*60)

meilleur_modele = perf_df.index[0]
meilleur_r2 = perf_df.iloc[0]['R2']

print(f"ü•á MEILLEUR MOD√àLE: {meilleur_modele}")
print(f"   Score R¬≤: {meilleur_r2:.4f}")
print(f"   RMSE: {perf_df.iloc[0]['RMSE']:,.0f}")
print("\nüìã R√©sum√©:")
print("- Les mod√®les d'ensemble (Gradient Boosting, For√™t Al√©atoire) surpassent les mod√®les lin√©aires")
print("- Les relations prix/caract√©ristiques sont non-lin√©aires et complexes")
print("- Optimisation hyperparam√®tres recommand√©e pour le meilleur mod√®le")

print("\nüéâ Analyse compl√®te termin√©e avec succ√®s!")
print(f"Dataset initial: {df.shape}")
print(f"Dataset final: {df_processed.shape}")
print(f"Meilleur R¬≤ obtenu: {meilleur_r2:.4f}")
